# Explainable-machine-learning-project-on-FIFA-world-cup-dataset
Explainable AI is a crucial class of AI models that finds valuable applications in business settings. However, it is essential to effectively communicate and explain the behavior of our code to business associates beyond just writing the code itself.

To connect the behavior of our machine learning (ML) models to the business case and reality, ML engineers should possess good domain knowledge. This knowledge enables them to articulate their decision-making process while building the ML algorithm. They can address questions such as:

1. Why did you choose a particular model over the other?
2. What are the key differences in feature behavior that influenced your algorithm selection?
3. How does the behavior of your algorithm relate to real business cases?

In this specific project, I employed the dataset provided for the 2018 FIFA World Cup to construct classifiers that identify matches producing the "man of the match" using significant football game events and properties. I utilized the RandomForestClassifier and DecisionTree classifier for this prediction task and thoroughly investigated and explained the behavior of each model.
